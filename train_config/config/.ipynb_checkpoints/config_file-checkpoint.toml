[model_arguments]
#两者同时设置为true时，开启Stable Diffusion V2版本的训练。
v2 = false
v_parameterization = false
pretrained_model_name_or_path = "/root/autodl-tmp/SD-Train/model/stable-diffusion-v1-5"   #SD模型地址

[optimizer_arguments]
optimizer_type = "AdamW"  #一共有：["AdamW"(default), "AdamW8bit", "Lion", "SGDNesterov", "SGDNesterov8bit", "DAdaptation", "AdaFactor"]七种优化器可以选择。
learning_rate = 2e-6    #训练学习率，单卡推荐设置2e-6，多卡推荐设置1e-7。如果我们将学习率设置的过大，很有可能导致SD模型训练跑飞，在前向推理时生成非常差的图片；如果我们将学习率设置的过小，可能会导致模型无法跳出极小值点。
max_grad_norm = 1.0    #最大梯度范数，0表示没有clip，1表示将梯度clip到1。
train_text_encoder = false   #是否在SD模型训练时对Text Encoder进行微调，如果设置为true，则对Text Encoder进行微调。
lr_scheduler = "constant"   #设置学习率调度策略，可以设置成linear, cosine, cosine_with_restarts, polynomial, constant (default), constant_with_warmup, adafactor。
lr_warmup_steps = 0    #在启动学习率调度策略前，先固定学习率训练的步数。

[dataset_arguments]
debug_dataset = false   #训练时对数据进行debug处理，不让破损数据中断训练进程。
in_json = "/root/autodl-tmp/SD-Train/finetune/Dataset/meta_lat.json"    #读取数据集json文件，json文件中包含了数据名称，数据标签，数据分桶等信息。
train_data_dir = "/root/autodl-tmp/SD-Train/finetune/Dataset/datasets"   #读取本地数据集存放路径。
dataset_repeats = 1   #：整个数据集重复训练的次数，也可以理解为每个epoch中，训练集数据迭代的次数。（经验分享：如果数据量级小于一千，可以设置为10；如果数据量级在一千与一万之前，可以设置为5；如果数据量级大于一万，可以设置为2）
shuffle_caption = true   #当设置为true时，对训练标签进行打乱，能一定程度提高模型的泛化性。
keep_tokens = 0   #在训练过程中，会将txt中的tag`进行随机打乱。如果将keep tokens设置为n，那前n个token的顺序在训练过程中将不会被打乱。
resolution = "512,512"   #设置训练时的数据输入分辨率，分别是width和height。resolution设置为32的倍数，比如512、768、1024或者更大。设置越大的resolution，SD模型能从数据中学习到越多的信息，从而提升SD模型在推理阶段的出图效果。
caption_dropout_rate = 0   #针对一个数据丢弃全部标签的概率，默认为0。
caption_tag_dropout_rate = 0   #针对一个数据丢弃部分标签的概率，默认为0。（类似于传统深度学习的Dropout逻辑）
caption_dropout_every_n_epochs = 0   #训练n个epoch，将数据标签全部丢弃。
color_aug = false   #数据颜色增强，建议不启用，其与caching latents不兼容，若启用会导致训练时间大大增加（由于每次训练迭代时输入数据都会改变，无法提前获取 latents）。
token_warmup_min = 2   #在训练一开始学习每个数据的前n个tag（标签用逗号分隔后的前n个tag，比如girl，boy，good）
token_warmup_step = 0   #训练中学习标签数达到最大值所需的步数，默认为0，即一开始就能学习全部的标签。

[training_arguments]
output_dir = "/root/autodl-tmp/SD-Train/model/pre_model"   #模型保存的路径。
output_name = "sd_ts"   #模型名称。
save_precision = "fp16"   #模型保存的精度，一共有[“None”, "float", "fp16", "bf16"]四种选择，默认为“None”，即FP32精度。
save_n_epoch_ratio = 100   #每n个steps保存一次模型权重。
save_state = false   #设置为true时，每次保存模型权重的同时会额外保存训练状态（包括优化器状态等）。
train_batch_size = 2   #训练Batch-Size，与传统深度学习一致。
max_token_length = 225   #设置Text Encoder最大的Token数，有[None, 150, 225]三种选择，默认为“None”，即75。
mem_eff_attn = false   #对Cross Attention进行轻量化
xformers = true   #插件可以使SDXL模型在训练时显存减少一半左右。
max_train_steps = 100000   #SD模型训练的总步数。
max_data_loader_n_workers = 8   #数据加载的DataLoader worker数量，默认为8
persistent_data_loader_workers = true   #能够让DataLoader worker持续挂载，减少训练中每个epoch之间的数据读取时间，但是会增加内存消耗。
gradient_checkpointing = false   #设为true时开启梯度检查，通过以更长的计算时间为代价，换取更少的显存占用。相比于原本需要存储所有中间变量以供反向传播使用，使用了checkpoint的部分不存储中间变量而是在反向传播过程中重新计算这些中间变量。模型中的任何部分都可以使用gradient checkpoint。
gradient_accumulation_steps = 1   #如果显存不足，我们可以使用梯度累积步数，默认为1。
mixed_precision = "fp16"   #训练中是否使用混合精度，一共有["no", "fp16", "bf16"]三种选择，默认为“no”。
clip_skip = 1   #当设置clip_skip为2时，提取CLIP Text Encoder倒数第二层的输出；如果设置clip_skip为1，则提取CLIP Text Encoder倒数最后一层的输出。 CLIP Text Encoder模型一共有12层，越往深层模型输出的特征就越抽象，跳过过于抽象的信息可以防止过拟合。Rocky推荐二次元模型选择 clip_skip = 2，三次元模型选择 clip_skip = 1。
logging_dir = "/root/autodl-tmp/SD-Train/model/pre_model"   #设置训练log保存的路径。
log_prefix = "sd_ts"   #增加log文件的文件名前缀，比如sd_finetune_WeThinkIn1234567890。

[sample_prompt_arguments]
sample_every_n_steps = 1000   #在训练中每n步测试一次模型效果。
sample_sampler = "ddim"   #设置训练中测试模型效果时使用的sampler，可以选择["ddim","pndm","lms","euler","euler_a","heun","dpm_2","dpm_2_a","dpmsolver","dpmsolver++","dpmsingle", "k_lms","k_euler","k_euler_a","k_dpm_2","k_dpm_2_a"]，默认是“ddim”。

[saving_arguments]
save_model_as = "safetensors"  #每次模型权重保存时的格式，可以选择["ckpt", "safetensors", "diffusers", "diffusers_safetensors"]，目前SD WebUI兼容"ckpt"和"safetensors"格式模型。
